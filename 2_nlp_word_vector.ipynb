{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H P\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter \n",
    "#from gensim.models.tfidfmodel import TfidfModel\n",
    "#from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the Text File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data.txt', 'r')\n",
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Project Gutenberg EBook of Man to Man, by Jackson Gregory\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.org\\n\\n\\nTitle: Man to Man\\n\\nAuthor: Jackson Gregory\\n\\nRelease Date: July 29, 2006 [EBook #18933]\\n\\nLanguage: English\\n\\n\\n*** START OF THIS PROJECT GUTENBERG EBOOK MAN TO MAN ***\\n\\n\\n\\n\\nProduced by Al Haines\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[Frontispiece: The blazing heat was such that men and horses and steers\\nsuffered terribly.]\\n\\n\\n\\n\\n\\n\\nMAN TO MAN\\n\\n\\nBY\\n\\nJACKSON GREGORY\\n\\n\\n\\nAUTHOR OF\\n\\nJUDITH OF BLUE LAKE RANCH, THE BELLS OF SAN JUAN, SIX FEET FOUR, ETC.\\n\\n\\n\\n\\nILLUSTRATED BY\\n\\nJ. G. SHEPHERD\\n\\n\\n\\n\\n\\nGROSSET & DUNLAP\\n\\nPUBLISHERS -------- NEW YORK\\n\\n\\n\\n\\nCOPYRIGHT, 1920, BY\\n\\nCHARLES SCRIBNER'S SONS\\n\\n\\nPublished October, 1920\\n\\n\\n\\n\\nCONTENTS\\n\\n\\nCHAPTER\\n\\n     I. STEVE DIVES INTO DEEP WATERS\\n    II. MISS BLUE CLOAK KNOWS WHEN SHE'S BEAT\\n \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'laf.org/donate\\n\\n\\nSection 5.  General Information About Project Gutenberg-tm electronic\\nworks.\\n\\nProfessor Michael S. Hart is the originator of the Project Gutenberg-tm\\nconcept of a library of electronic works that could be freely shared\\nwith anyone.  For thirty years, he produced and distributed Project\\nGutenberg-tm eBooks with only a loose network of volunteer support.\\n\\n\\nProject Gutenberg-tm eBooks are often created from several printed\\neditions, all of which are confirmed as Public Domain in the U.S.\\nunless a copyright notice is included.  Thus, we do not necessarily\\nkeep eBooks in compliance with any particular paper edition.\\n\\n\\nMost people start at our Web site which has the main PG search facility:\\n\\n     http://www.gutenberg.org\\n\\nThis Web site includes information about Project Gutenberg-tm,\\nincluding how to make donations to the Project Gutenberg Literary\\nArchive Foundation, how to help produce our new eBooks, and how to\\nsubscribe to our email newsletter to hear about new eBooks.\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436574"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentences Tokenization and lowercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_split=text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg EBook of Man to Man, by Jackson Gregory',\n",
       " '',\n",
       " 'This eBook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  You may copy it, give it away or',\n",
       " 're-use it under the terms of the Project Gutenberg License included']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_split[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens=sent_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of man to man, by jackson gregory\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.',\n",
       " 'you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.org\\n\\n\\ntitle: man to man\\n\\nauthor: jackson gregory\\n\\nrelease date: july 29, 2006 [ebook #18933]\\n\\nlanguage: english\\n\\n\\n*** start of this project gutenberg ebook man to man ***\\n\\n\\n\\n\\nproduced by al haines\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[frontispiece: the blazing heat was such that men and horses and steers\\nsuffered terribly.]',\n",
       " 'man to man\\n\\n\\nby\\n\\njackson gregory\\n\\n\\n\\nauthor of\\n\\njudith of blue lake ranch, the bells of san juan, six feet four, etc.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5551"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus = []\n",
    "\n",
    "#for cumle in sent_tokens:\n",
    "    #corpus.append(cumle.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=word_tokenize(sent_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(len(sent_tokens)):\n",
    "    corpus.append(word_tokenize(sent_tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'of',\n",
       "  'man',\n",
       "  'to',\n",
       "  'man',\n",
       "  ',',\n",
       "  'by',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'this',\n",
       "  'ebook',\n",
       "  'is',\n",
       "  'for',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'anyone',\n",
       "  'anywhere',\n",
       "  'at',\n",
       "  'no',\n",
       "  'cost',\n",
       "  'and',\n",
       "  'with',\n",
       "  'almost',\n",
       "  'no',\n",
       "  'restrictions',\n",
       "  'whatsoever',\n",
       "  '.'],\n",
       " ['you',\n",
       "  'may',\n",
       "  'copy',\n",
       "  'it',\n",
       "  ',',\n",
       "  'give',\n",
       "  'it',\n",
       "  'away',\n",
       "  'or',\n",
       "  're-use',\n",
       "  'it',\n",
       "  'under',\n",
       "  'the',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'the',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'license',\n",
       "  'included',\n",
       "  'with',\n",
       "  'this',\n",
       "  'ebook',\n",
       "  'or',\n",
       "  'online',\n",
       "  'at',\n",
       "  'www.gutenberg.org',\n",
       "  'title',\n",
       "  ':',\n",
       "  'man',\n",
       "  'to',\n",
       "  'man',\n",
       "  'author',\n",
       "  ':',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'release',\n",
       "  'date',\n",
       "  ':',\n",
       "  'july',\n",
       "  '29',\n",
       "  ',',\n",
       "  '2006',\n",
       "  '[',\n",
       "  'ebook',\n",
       "  '#',\n",
       "  '18933',\n",
       "  ']',\n",
       "  'language',\n",
       "  ':',\n",
       "  'english',\n",
       "  '***',\n",
       "  'start',\n",
       "  'of',\n",
       "  'this',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'man',\n",
       "  'to',\n",
       "  'man',\n",
       "  '***',\n",
       "  'produced',\n",
       "  'by',\n",
       "  'al',\n",
       "  'haines',\n",
       "  '[',\n",
       "  'frontispiece',\n",
       "  ':',\n",
       "  'the',\n",
       "  'blazing',\n",
       "  'heat',\n",
       "  'was',\n",
       "  'such',\n",
       "  'that',\n",
       "  'men',\n",
       "  'and',\n",
       "  'horses',\n",
       "  'and',\n",
       "  'steers',\n",
       "  'suffered',\n",
       "  'terribly',\n",
       "  '.',\n",
       "  ']'],\n",
       " ['man',\n",
       "  'to',\n",
       "  'man',\n",
       "  'by',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'author',\n",
       "  'of',\n",
       "  'judith',\n",
       "  'of',\n",
       "  'blue',\n",
       "  'lake',\n",
       "  'ranch',\n",
       "  ',',\n",
       "  'the',\n",
       "  'bells',\n",
       "  'of',\n",
       "  'san',\n",
       "  'juan',\n",
       "  ',',\n",
       "  'six',\n",
       "  'feet',\n",
       "  'four',\n",
       "  ',',\n",
       "  'etc',\n",
       "  '.']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5551"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Punctuation, numbers and undesired characters like\"*\", \"#\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_1=[]\n",
    "for i in range(len(corpus)):\n",
    "    corpus_new=[w for w in corpus[i] if w.isalpha()]\n",
    "    corpus_1.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'of',\n",
       "  'man',\n",
       "  'to',\n",
       "  'man',\n",
       "  'by',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'this',\n",
       "  'ebook',\n",
       "  'is',\n",
       "  'for',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'anyone',\n",
       "  'anywhere',\n",
       "  'at',\n",
       "  'no',\n",
       "  'cost',\n",
       "  'and',\n",
       "  'with',\n",
       "  'almost',\n",
       "  'no',\n",
       "  'restrictions',\n",
       "  'whatsoever'],\n",
       " ['you',\n",
       "  'may',\n",
       "  'copy',\n",
       "  'it',\n",
       "  'give',\n",
       "  'it',\n",
       "  'away',\n",
       "  'or',\n",
       "  'it',\n",
       "  'under',\n",
       "  'the',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'the',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'license',\n",
       "  'included',\n",
       "  'with',\n",
       "  'this',\n",
       "  'ebook',\n",
       "  'or',\n",
       "  'online',\n",
       "  'at',\n",
       "  'title',\n",
       "  'man',\n",
       "  'to',\n",
       "  'man',\n",
       "  'author',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'release',\n",
       "  'date',\n",
       "  'july',\n",
       "  'ebook',\n",
       "  'language',\n",
       "  'english',\n",
       "  'start',\n",
       "  'of',\n",
       "  'this',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'man',\n",
       "  'to',\n",
       "  'man',\n",
       "  'produced',\n",
       "  'by',\n",
       "  'al',\n",
       "  'haines',\n",
       "  'frontispiece',\n",
       "  'the',\n",
       "  'blazing',\n",
       "  'heat',\n",
       "  'was',\n",
       "  'such',\n",
       "  'that',\n",
       "  'men',\n",
       "  'and',\n",
       "  'horses',\n",
       "  'and',\n",
       "  'steers',\n",
       "  'suffered',\n",
       "  'terribly']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_1[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_2=[]\n",
    "for i in range(len(corpus_1)):\n",
    "    corpus_new=[t for t in corpus_1[i] if t not in stop_words]\n",
    "    corpus_2.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'man',\n",
       "  'man',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'ebook',\n",
       "  'use',\n",
       "  'anyone',\n",
       "  'anywhere',\n",
       "  'cost',\n",
       "  'almost',\n",
       "  'restrictions',\n",
       "  'whatsoever'],\n",
       " ['may',\n",
       "  'copy',\n",
       "  'give',\n",
       "  'away',\n",
       "  'terms',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'license',\n",
       "  'included',\n",
       "  'ebook',\n",
       "  'online',\n",
       "  'title',\n",
       "  'man',\n",
       "  'man',\n",
       "  'author',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'release',\n",
       "  'date',\n",
       "  'july',\n",
       "  'ebook',\n",
       "  'language',\n",
       "  'english',\n",
       "  'start',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'man',\n",
       "  'man',\n",
       "  'produced',\n",
       "  'al',\n",
       "  'haines',\n",
       "  'frontispiece',\n",
       "  'blazing',\n",
       "  'heat',\n",
       "  'men',\n",
       "  'horses',\n",
       "  'steers',\n",
       "  'suffered',\n",
       "  'terribly']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem=WordNetLemmatizer()\n",
    "corpus_3=[]\n",
    "for i in range(len(corpus_2)):\n",
    "    corpus_new=[lem.lemmatize(t) for t in corpus_2[i]]\n",
    "    corpus_3.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'man',\n",
       "  'man',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'ebook',\n",
       "  'use',\n",
       "  'anyone',\n",
       "  'anywhere',\n",
       "  'cost',\n",
       "  'almost',\n",
       "  'restriction',\n",
       "  'whatsoever'],\n",
       " ['may',\n",
       "  'copy',\n",
       "  'give',\n",
       "  'away',\n",
       "  'term',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'license',\n",
       "  'included',\n",
       "  'ebook',\n",
       "  'online',\n",
       "  'title',\n",
       "  'man',\n",
       "  'man',\n",
       "  'author',\n",
       "  'jackson',\n",
       "  'gregory',\n",
       "  'release',\n",
       "  'date',\n",
       "  'july',\n",
       "  'ebook',\n",
       "  'language',\n",
       "  'english',\n",
       "  'start',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'man',\n",
       "  'man',\n",
       "  'produced',\n",
       "  'al',\n",
       "  'haines',\n",
       "  'frontispiece',\n",
       "  'blazing',\n",
       "  'heat',\n",
       "  'men',\n",
       "  'horse',\n",
       "  'steer',\n",
       "  'suffered',\n",
       "  'terribly']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_3[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WORD VECTORS:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. word2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus_3, size=100, window=3, min_count=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'man',\n",
       " 'gregory',\n",
       " 'use',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'cost',\n",
       " 'almost']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.62377488e-02,  8.12551081e-02, -1.56524658e-01,  1.29062304e-04,\n",
       "       -1.67993680e-01,  3.73202600e-02,  1.62039846e-01,  3.17077786e-01,\n",
       "       -1.30747175e-02, -7.71819055e-02, -8.10408443e-02, -6.83511123e-02,\n",
       "        2.25369744e-02,  5.23752384e-02,  1.49758616e-02,  1.02254339e-01,\n",
       "        2.24439889e-01,  8.84020999e-02,  2.37878129e-01, -3.11563406e-02,\n",
       "        1.62848532e-01,  8.71576443e-02, -2.83551589e-02,  7.81731606e-02,\n",
       "        9.01429728e-02, -4.69373055e-02,  2.53982335e-01, -2.10345253e-01,\n",
       "        1.52662203e-01,  1.49409547e-01,  1.96904726e-02,  1.94627903e-02,\n",
       "        4.26807962e-02,  1.54743999e-01,  1.32455826e-01, -8.76791552e-02,\n",
       "        1.27146363e-01,  2.15699911e-01, -2.31481433e-01,  2.13151425e-01,\n",
       "        2.37874791e-01,  5.85019067e-02,  7.70598203e-02, -1.19137488e-01,\n",
       "       -2.19245697e-03, -2.68623363e-02,  2.37337574e-01,  1.21148758e-01,\n",
       "       -1.70894209e-02, -1.12759203e-01,  3.10672466e-02, -1.49727196e-01,\n",
       "       -3.53313647e-02,  1.42518431e-01, -4.32246849e-02, -2.89519820e-02,\n",
       "       -1.33867800e-01, -9.42159370e-02,  1.87610835e-01,  1.06305033e-01,\n",
       "        5.35266139e-02, -6.21508621e-02, -3.30993719e-02,  2.07584649e-01,\n",
       "       -2.15753227e-01,  2.29599372e-01,  9.77614149e-02,  1.44586131e-01,\n",
       "        2.41682753e-02,  3.67429629e-02,  2.89309323e-01, -2.98902523e-02,\n",
       "       -2.00175002e-01, -1.96114108e-02, -9.76665169e-02, -2.71009821e-02,\n",
       "        1.27021909e-01,  1.58844963e-01,  1.09134376e-01, -1.63060755e-01,\n",
       "        3.27258222e-02,  2.76984483e-01,  1.13690831e-01,  1.03715379e-02,\n",
       "       -2.06962749e-01, -3.82458001e-01,  2.07342580e-01, -2.69989204e-02,\n",
       "        2.31850035e-02,  1.01940803e-01,  1.35353446e-01, -9.01599452e-02,\n",
       "        5.63307703e-02, -1.47407398e-01, -1.84991404e-01,  5.76758198e-03,\n",
       "        1.38819367e-01,  7.71154985e-02, -2.32282784e-02, -5.49090803e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('thought', 0.9990807175636292),\n",
       " ('cried', 0.9990256428718567),\n",
       " ('heavily', 0.999002993106842),\n",
       " ('packard', 0.9989368915557861),\n",
       " ('fool', 0.9989358186721802),\n",
       " ('would', 0.9989358186721802),\n",
       " ('tell', 0.9989319443702698),\n",
       " ('take', 0.9989233613014221),\n",
       " ('laughed', 0.99891597032547),\n",
       " ('say', 0.9989094734191895)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('afternoon', 0.9995065927505493),\n",
       " ('already', 0.9994897842407227),\n",
       " ('shadow', 0.9994802474975586),\n",
       " ('soul', 0.9994798302650452),\n",
       " ('white', 0.9994782209396362),\n",
       " ('part', 0.999472439289093),\n",
       " ('life', 0.9994680881500244),\n",
       " ('rose', 0.9994679093360901),\n",
       " ('unless', 0.999467670917511),\n",
       " ('domain', 0.99946129322052)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('floor', 0.9995653629302979),\n",
       " ('making', 0.999564528465271),\n",
       " ('cattle', 0.9995615482330322),\n",
       " ('anger', 0.9995465278625488),\n",
       " ('stand', 0.9995442032814026),\n",
       " ('gun', 0.9995408058166504),\n",
       " ('found', 0.9995406866073608),\n",
       " ('arm', 0.9995352625846863),\n",
       " ('nothing', 0.9995307922363281),\n",
       " ('made', 0.9995301365852356)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('car')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Putting All Together** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('alice.txt', 'r', encoding='latin-1')\n",
    "text2 = f2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens=sent_tokenize(text2.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8537"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(len(sent_tokens)):\n",
    "    corpus.append(word_tokenize(sent_tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_1=[]\n",
    "for i in range(len(corpus)):\n",
    "    corpus_new=[w for w in corpus[i] if w.isalpha()]\n",
    "    corpus_1.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "corpus_2=[]\n",
    "for i in range(len(corpus_1)):\n",
    "    corpus_new=[t for t in corpus_1[i] if t not in stop_words]\n",
    "    corpus_2.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem=WordNetLemmatizer()\n",
    "corpus_3=[]\n",
    "for i in range(len(corpus_2)):\n",
    "    corpus_new=[lem.lemmatize(t) for t in corpus_2[i]]\n",
    "    corpus_3.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus_3, size=100, window=3, min_count=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'dracula',\n",
       " 'bram',\n",
       " 'stoker',\n",
       " 'use',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'cost',\n",
       " 'almost',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'give',\n",
       " 'away',\n",
       " 'term',\n",
       " 'license',\n",
       " 'included',\n",
       " 'online',\n",
       " 'title',\n",
       " 'date',\n",
       " 'august',\n",
       " 'language',\n",
       " 'english',\n",
       " 'start',\n",
       " 'produced',\n",
       " 'distributed',\n",
       " 'http',\n",
       " 'file',\n",
       " 'image']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13465297, -0.16180933, -0.01200599,  0.1857682 ,  0.00290473,\n",
       "        0.00629612,  0.19061238, -0.22476858, -0.00684372, -0.11111883,\n",
       "       -0.046813  ,  0.14275849, -0.17494264, -0.06341972,  0.10145415,\n",
       "        0.10091238,  0.22431289, -0.04474512,  0.06165235,  0.13876566,\n",
       "        0.01328606,  0.20130877,  0.16992384, -0.06349722, -0.08242462,\n",
       "       -0.13628677,  0.10404386,  0.05651031,  0.13308746,  0.12452218,\n",
       "        0.1766647 ,  0.2237424 , -0.2574027 ,  0.12159391, -0.25388402,\n",
       "       -0.09741031, -0.04438654,  0.0079407 , -0.01727061, -0.16407324,\n",
       "        0.19319533, -0.0204979 ,  0.25040647,  0.01719492,  0.03039811,\n",
       "        0.18060525, -0.00873336,  0.2075212 ,  0.10613585, -0.05412236,\n",
       "        0.30039528, -0.08949514, -0.01029238, -0.00672307,  0.19175042,\n",
       "       -0.06152694, -0.17449644, -0.0255851 ,  0.17555772, -0.13541347,\n",
       "        0.11664715, -0.04070672,  0.2728497 ,  0.22064336,  0.17956851,\n",
       "       -0.09720805, -0.01866934, -0.19329032,  0.05581016, -0.14801101,\n",
       "        0.00773916, -0.06158781,  0.08855606, -0.14514925, -0.18135983,\n",
       "        0.11266752, -0.06169425,  0.00860567, -0.0808171 , -0.06004117,\n",
       "       -0.04673769, -0.13094759,  0.08521781,  0.1724831 ,  0.01091552,\n",
       "       -0.240627  , -0.06970523, -0.01816279, -0.00246992, -0.19200292,\n",
       "       -0.13230957, -0.1355447 ,  0.24651611, -0.14904094,  0.191156  ,\n",
       "        0.20285617,  0.03698861, -0.15490453, -0.11887932, -0.2886345 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('death', 0.9990698099136353),\n",
       " ('new', 0.9988647103309631),\n",
       " ('give', 0.9987469911575317),\n",
       " ('men', 0.9986183643341064),\n",
       " ('power', 0.9986178874969482),\n",
       " ('soul', 0.9986152648925781),\n",
       " ('free', 0.9985696077346802),\n",
       " ('die', 0.9985000491142273),\n",
       " ('world', 0.9984984397888184),\n",
       " ('end', 0.9984952807426453)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nltk corpus methond-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', 'VOLUME', 'I', 'CHAPTER']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.StreamBackedCorpusView"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nltk corpus methond-2 (reaching raw corpus)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg as gt\n",
    "print(gt.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', ...]\n"
     ]
    }
   ],
   "source": [
    "shakespeare_macbeth = gt.words(\"shakespeare-macbeth.txt\")\n",
    "print(shakespeare_macbeth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Macbeth by William Shakespeare 1603]\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "Thunder and Lig\n"
     ]
    }
   ],
   "source": [
    "raw = gt.raw(\"shakespeare-macbeth.txt\")\n",
    "print(raw[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens=sent_tokenize(raw.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1420"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(len(sent_tokens)):\n",
    "    corpus.append(word_tokenize(sent_tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_1=[]\n",
    "for i in range(len(corpus)):\n",
    "    corpus_new=[w for w in corpus[i] if w.isalpha()]\n",
    "    corpus_1.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "corpus_2=[]\n",
    "for i in range(len(corpus_1)):\n",
    "    corpus_new=[t for t in corpus_1[i] if t not in stop_words]\n",
    "    corpus_2.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem=WordNetLemmatizer()\n",
    "corpus_3=[]\n",
    "for i in range(len(corpus_2)):\n",
    "    corpus_new=[lem.lemmatize(t) for t in corpus_2[i]]\n",
    "    corpus_3.append(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus_3, size=100, window=3, min_count=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macbeth',\n",
       " 'actus',\n",
       " 'prima',\n",
       " 'thunder',\n",
       " 'enter',\n",
       " 'three',\n",
       " 'witch',\n",
       " 'shall',\n",
       " 'meet',\n",
       " 'againe',\n",
       " 'done',\n",
       " 'lost',\n",
       " 'ere',\n",
       " 'set',\n",
       " 'place',\n",
       " 'vpon',\n",
       " 'come',\n",
       " 'call',\n",
       " 'anon',\n",
       " 'faire',\n",
       " 'foule',\n",
       " 'ayre',\n",
       " 'exeunt',\n",
       " 'scena',\n",
       " 'secunda',\n",
       " 'alarum',\n",
       " 'within',\n",
       " 'king',\n",
       " 'donalbaine',\n",
       " 'lenox']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01065214, -0.04625022,  0.0395883 , -0.03720452,  0.01717621,\n",
       "        0.02964413, -0.01740702, -0.02234402, -0.03626255,  0.03460313,\n",
       "       -0.01974946,  0.02786998,  0.0068853 , -0.04511343, -0.00492597,\n",
       "        0.04808065,  0.0468384 ,  0.00985552,  0.00487402,  0.04078983,\n",
       "        0.02587378,  0.02319846,  0.01478348,  0.0606999 , -0.02443204,\n",
       "       -0.01728195, -0.02292331,  0.03440556,  0.02230506, -0.03695389,\n",
       "        0.03369768,  0.00505647, -0.00646191, -0.04493668, -0.02308217,\n",
       "        0.00079732,  0.00258686,  0.0037005 , -0.00675933, -0.06256483,\n",
       "        0.01663237,  0.03224978, -0.03249802,  0.04841669, -0.00637942,\n",
       "        0.04747624, -0.0134402 ,  0.03674602,  0.02177614, -0.02474593,\n",
       "        0.04055872, -0.01864001, -0.03252444,  0.04929685,  0.02192749,\n",
       "        0.03090333, -0.03741485,  0.0164503 ,  0.04297265, -0.06593891,\n",
       "        0.01859949,  0.01420963, -0.03119434,  0.00402068, -0.02963622,\n",
       "       -0.04567606, -0.03838712,  0.00414623,  0.00998483, -0.00871573,\n",
       "        0.01464023,  0.01274157, -0.01556834,  0.01577702, -0.03691638,\n",
       "        0.00650843, -0.01359016,  0.04420455,  0.0753997 , -0.01371878,\n",
       "       -0.01592513, -0.00776541, -0.02315117,  0.01703696,  0.02040318,\n",
       "        0.02831882,  0.02665484,  0.00473319, -0.08015933, -0.05265086,\n",
       "       -0.04285399,  0.04020957,  0.05043101,  0.07031741,  0.04599073,\n",
       "        0.00513178,  0.02666284,  0.00858628, -0.04611655, -0.08400703],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shall', 0.9955843091011047),\n",
       " ('make', 0.9953697919845581),\n",
       " ('hath', 0.9948759078979492),\n",
       " ('thy', 0.9946627616882324),\n",
       " ('thee', 0.9946516156196594),\n",
       " ('must', 0.9945406317710876),\n",
       " ('v', 0.9944364428520203),\n",
       " ('thou', 0.9941587448120117),\n",
       " ('would', 0.9941101670265198),\n",
       " ('haue', 0.9940223097801208)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('king')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
